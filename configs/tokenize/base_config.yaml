logging:
  enable_wandb: false
  summaries_stdout: true
  project_name: 'tokenization'
  run_name: null  # select random name
  run_description: null
  log_dir: null # wo=ill be set to output folder
  log_filename: 'log.txt'
  summaries_filename: 'summaries.txt'
  allow_overwrite_log: true
  metrics_type: null

data:
  # dataset settings
  hf_name_path: null # dataset path, '$DATA_ROOT/datasets/tinystories_v2/'
  hf_dataset_name: null
  hf_data_dir: null
  hf_data_files: null
  hf_sample_by: null
  hf_revision: null
  hf_cache_dir: null
  text_column: 'text'

  # splits to tokenize
  train_split: null # auto detect 'train'
  val_split: null # set to '' to ignore existing val split and create a new one
  test_split: null # auto detect 'train'
  val_fraction: null
  test_fraction: null

  data_loader_seed: 8

  tokenized_out_dir: null # '$DATA_ROOT/datasets/tokenized/tinystories_v2/tiktoken/'
