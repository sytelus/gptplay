__include__: ['base_config.yaml']

tokenizer:
  module: 'nanugpt.tokenizers.hf_tokenizer.get_tokenizer_factory'
  module_kwargs:
    hf_path: 'NousResearch/Llama-2-7b-hf'
    token: '$HF_AUTH_TOKEN'
    fix_pad_token: false

data:
  hf_name_path: 'text'
  hf_data_files: {train: ['$DATA_ROOT/datasets/tinyshakespeare/input.txt']}
  tokenized_out_dir: '$DATA_ROOT/tokenized/tinyshakespeare/llama2/'
  hf_sample_by: 'paragraph'

  val_fraction: 0.1
  text_column: null