__include__: ['base_config.yaml']

general:
  project_name: 'gpt2o_tinystories'

data:
  module_kwargs:
    tokenized_train_path: '$DATA_ROOT/tokenized/tinystories_v2/tiktoken/train.bin'
    tokenized_val_path: '$DATA_ROOT/tokenized/tinystories_v2/tiktoken/validation.bin'

training:
  #device_batch_size: 60
  max_steps: 37500
  #global_batch_size: 480

# optimizer:
#   module: 'nanugpt.optimizers.adamw_nanogpt.get_optim'
#   module_kwargs:
#     learning_rate: 6.0E-4
#     weight_decay: 0.1
#     beta1: 0.9
#     beta2: 0.95
#     eps: 1.0E-8 # pytorch default

# scheduler:
#   module: 'nanugpt.schedulers.cosine.get_scheduler'
#   module_kwargs:
#     warmup_iters: 2000
#     end_factor: 1.0E-2

