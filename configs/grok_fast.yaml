__include__: wandb.yaml

# This config uses weight decay to speed up things

# transformer
num_layers: 2
dim_model: 128
num_heads: 4

# data
operation: 'x/y'
training_fraction: 0.5
prime: 97
batch_size: 512

# training
learning_rate: 1.0E-3
weight_decay: 0.1     # weight_decay=1 makes things unstable with lots of loss spikes
num_steps: 100000
device: ''            # auto select or cpu, cuda
eval_every: 100
seed: 42