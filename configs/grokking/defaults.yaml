general:
  device: ''            # auto select or cpu, cuda
  seed: 42
  out_dir: '~/out_dir/grokking'

logging:
  enable_wandb: false
  project_name: grokking
  run_name: nil  # select random name
  run_description: nil
  log_dir: '~/out_dir/grokking'
  log_filename: 'log.txt'
  allow_overwrite_log: true
  metrics_type: 'classification'

model:
  num_layers: 2
  dim_model: 128
  num_heads: 4
  seq_len: 5 # currently each input eq has [eos a op b =] which is 5 tokens

data:
  operation: 'x/y'
  training_fraction: 0.5
  val_fraction: null # if null, use 1 - training_fraction, test fraction is 0
  batch_size: 512
  eval_batch_size: 32768 # 2^15=32768
  data_loader_seed: 8

training:
  num_steps: 3000    # 1e5 is not enough when weight_decay=0.0
  log_every: 100

optimizer:
  learning_rate: 1.0E-3
  weight_decay: 0.1     # weight_decay=1 makes convergence much faster and original graph is not reproducible
  beta1: 0.9
  beta2: 0.98
  eps: 1.0E-8 # pytorch default

scheduler:
  start_factor: 1.0E-8
  total_iters: 10

eval:
  eval_every: 500