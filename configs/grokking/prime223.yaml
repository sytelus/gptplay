__include__: ['base_config.yaml']

# standard baseline with prime 223, reproduces grokking in 10k steps

data:
  module_kwargs:
    training_fraction: 0.5
    val_fraction: null # if null, use 1 - training_fraction
    prime: &prime 223

training:
  max_steps: 10000

tokenizer:
  module_kwargs:
    prime: *prime

optimizer:
  module_kwargs:
    weight_decay: 0.1     # weight_decay=1 makes convergence much faster and original graph is not reproducible
