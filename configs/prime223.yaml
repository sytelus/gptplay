__include__: wandb.yaml

# transformer
num_layers: 2
dim_model: 128
num_heads: 4

# data
operation: 'x/y'
training_fraction: 0.5
prime: 223
batch_size: 512

# training
learning_rate: 1.0E-3
weight_decay: 0.1     # weight_decay=1 makes convergence much faster and original graph is not reproducible
num_steps: 10000    # 1e5 is not enough when weight_decay=0.0
device: ''            # auto select or cpu, cuda
eval_every: 100
seed: 42